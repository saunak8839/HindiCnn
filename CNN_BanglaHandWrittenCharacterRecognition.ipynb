{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Saunak\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', input_shape = (28, 28, 3)))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2),strides=2))\n",
    "#classifier.add(Dropout(.2))\n",
    "\n",
    "classifier.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu',padding='same'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "#classifier.add(Dropout(.2))\n",
    "\n",
    "classifier.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu',padding='valid'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2),strides=2))\n",
    "#classifier.add(Dropout(.2))\n",
    "\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(units = 64, activation = 'relu'))\n",
    "#classifier.add(Dropout(.2))\n",
    "classifier.add(Dense(128,activation=\"relu\"))\n",
    "\n",
    "classifier.add(Dense(units = 46, activation = 'softmax'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the CNN model to the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import ImageFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78200 images belonging to 46 classes.\n",
      "Found 13800 images belonging to 46 classes.\n"
     ]
    }
   ],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = .2, rotation_range = 25)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('archive\\DevanagariHandwrittenCharacterDataset\\Train', target_size = (28, 28), \n",
    "                                                 batch_size = 1, class_mode = 'categorical')\n",
    "test_set = test_datagen.flow_from_directory('archive\\DevanagariHandwrittenCharacterDataset\\Test', target_size = (28, 28), \n",
    "                                                 batch_size = 1, class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78200"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13800"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saunak\\AppData\\Local\\Temp\\ipykernel_21524\\593750664.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  classifier.fit_generator(training_set, steps_per_epoch = 5000, epochs = 30,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 45s 9ms/step - loss: 0.5932 - accuracy: 0.8160 - val_loss: 0.4875 - val_accuracy: 0.8648 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "5000/5000 [==============================] - 44s 9ms/step - loss: 0.5943 - accuracy: 0.8248 - val_loss: 0.4339 - val_accuracy: 0.8664 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "5000/5000 [==============================] - 44s 9ms/step - loss: 0.5867 - accuracy: 0.8298 - val_loss: 0.4316 - val_accuracy: 0.8728 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "5000/5000 [==============================] - 44s 9ms/step - loss: 0.5612 - accuracy: 0.8306 - val_loss: 0.4138 - val_accuracy: 0.8800 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "5000/5000 [==============================] - 43s 9ms/step - loss: 0.5479 - accuracy: 0.8416 - val_loss: 0.4102 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "5000/5000 [==============================] - 43s 9ms/step - loss: 0.5729 - accuracy: 0.8356 - val_loss: 0.5032 - val_accuracy: 0.8728 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "5000/5000 [==============================] - 43s 9ms/step - loss: 0.5841 - accuracy: 0.8256 - val_loss: 0.4528 - val_accuracy: 0.8744 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "5000/5000 [==============================] - 43s 9ms/step - loss: 0.5819 - accuracy: 0.8292 - val_loss: 0.6224 - val_accuracy: 0.8400 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "5000/5000 [==============================] - 43s 9ms/step - loss: 0.5825 - accuracy: 0.8314 - val_loss: 0.5144 - val_accuracy: 0.8728 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "5000/5000 [==============================] - 42s 8ms/step - loss: 0.5287 - accuracy: 0.8482 - val_loss: 0.4062 - val_accuracy: 0.8896 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "5000/5000 [==============================] - 42s 8ms/step - loss: 0.5543 - accuracy: 0.8470 - val_loss: 0.7084 - val_accuracy: 0.8440 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "5000/5000 [==============================] - 42s 8ms/step - loss: 0.5648 - accuracy: 0.8380 - val_loss: 0.4174 - val_accuracy: 0.8952 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "5000/5000 [==============================] - 42s 8ms/step - loss: 0.5546 - accuracy: 0.8424 - val_loss: 0.4577 - val_accuracy: 0.8744 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "5000/5000 [==============================] - 41s 8ms/step - loss: 0.5522 - accuracy: 0.8434 - val_loss: 0.4901 - val_accuracy: 0.8712 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.5578 - accuracy: 0.8318 - val_loss: 0.5432 - val_accuracy: 0.8800 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 0.5742 - accuracy: 0.8426 - val_loss: 0.4810 - val_accuracy: 0.8848 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 0.5442 - accuracy: 0.8488 - val_loss: 0.4298 - val_accuracy: 0.8864 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 0.5535 - accuracy: 0.8426 - val_loss: 0.3753 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 0.5411 - accuracy: 0.8496 - val_loss: 0.5248 - val_accuracy: 0.8832 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 0.5704 - accuracy: 0.8418 - val_loss: 0.5568 - val_accuracy: 0.8792 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 0.5640 - accuracy: 0.8458 - val_loss: 0.4462 - val_accuracy: 0.8960 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 0.5881 - accuracy: 0.8400 - val_loss: 0.3761 - val_accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 0.5266 - accuracy: 0.8562 - val_loss: 0.6509 - val_accuracy: 0.8648 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 0.5826 - accuracy: 0.8476 - val_loss: 0.4720 - val_accuracy: 0.8832 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "5000/5000 [==============================] - 41s 8ms/step - loss: 0.5609 - accuracy: 0.8428 - val_loss: 0.4208 - val_accuracy: 0.9072 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "5000/5000 [==============================] - 42s 8ms/step - loss: 0.5602 - accuracy: 0.8462 - val_loss: 0.5189 - val_accuracy: 0.8760 - lr: 0.0010\n",
      "Epoch 27/30\n",
      "5000/5000 [==============================] - 43s 9ms/step - loss: 0.5608 - accuracy: 0.8518 - val_loss: 0.4980 - val_accuracy: 0.8952 - lr: 0.0010\n",
      "Epoch 28/30\n",
      "5000/5000 [==============================] - 41s 8ms/step - loss: 0.6200 - accuracy: 0.8324 - val_loss: 0.5053 - val_accuracy: 0.8928 - lr: 0.0010\n",
      "Epoch 29/30\n",
      "5000/5000 [==============================] - 42s 8ms/step - loss: 0.6003 - accuracy: 0.8360 - val_loss: 0.3672 - val_accuracy: 0.8968 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "5000/5000 [==============================] - 41s 8ms/step - loss: 0.6168 - accuracy: 0.8356 - val_loss: 0.6259 - val_accuracy: 0.8520 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22088fbea10>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                  patience=5, min_lr=0.001)\n",
    "classifier.fit_generator(training_set, steps_per_epoch = 5000, epochs = 30,\n",
    "                        validation_data = test_set, validation_steps = 1250,callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_40 (Conv2D)          (None, 26, 26, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 13, 13, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPoolin  (None, 2, 2, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 50)                6450      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 140,850\n",
      "Trainable params: 140,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "classifier_json = classifier.to_json()\n",
    "\n",
    "with open(\"CNN_HindiHandWrittenCharacterRecognition.json\", \"w\") as json_file:\n",
    "    json_file.write(classifier_json)\n",
    "    \n",
    "classifier.save_weights(\"CNN_HindiHandWrittenCharacterRecognition.h5\")\n",
    "print('Saved model to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a graphical user interface to draw the character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import ImageTk, ImageDraw, Image\n",
    "from tkinter import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_image():\n",
    "    width = 256\n",
    "    height = 256\n",
    "    center = height // 2\n",
    "    white = (255, 255, 255)\n",
    "    green = (0, 128, 0)\n",
    "    \n",
    "    def save():\n",
    "        filename = 'C:\\\\Users\\Saunak\\Documents\\GitHub\\RegionalCharacterDetectionUsingCNN\\Dataset\\Dataset\\SinglePrediction\\image.jpg'\n",
    "        image.save(filename)\n",
    "        \n",
    "    def paint(event):\n",
    "        x1, y1 = (event.x - 1), (event.y - 1)\n",
    "        x2, y2 = (event.x + 1), (event.y + 1)\n",
    "        cv.create_oval(x1, y1, x2, y2, fill = 'black', width = 40)\n",
    "        draw.line([x1, y1, x2, y2], fill = 'black', width = 40)\n",
    "        \n",
    "    root = Tk()\n",
    "    \n",
    "    cv = Canvas(root, width = width, height = height, bg = 'white')\n",
    "    cv.pack()\n",
    "    \n",
    "    image = PIL.Image.new('RGB', (width, height), white)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    cv.pack(expand = YES, fill = BOTH)\n",
    "    cv.bind(\"<B1-Motion>\", paint)\n",
    "    \n",
    "    button = Button(text = 'Save', command = save)\n",
    "    button.pack()\n",
    "    \n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_character(res):\n",
    "    if res == 0:\n",
    "        print('prediction : অ')\n",
    "    elif res == 1:\n",
    "        print('prediction : আ')\n",
    "    elif res == 2:\n",
    "        print('prediction : ই')\n",
    "    elif res == 3:\n",
    "        print('prediction : ঈ')\n",
    "    elif res == 4:\n",
    "        print('prediction : উ')\n",
    "    elif res == 5:\n",
    "        print('prediction : ঊ')\n",
    "    elif res == 6:\n",
    "        print('prediction : ঋ')\n",
    "    elif res == 7:\n",
    "        print('prediction : এ')\n",
    "    elif res == 8:\n",
    "        print('prediction : ঐ')\n",
    "    elif res == 9:\n",
    "        print('prediction : ও')\n",
    "    elif res == 10:\n",
    "        print('prediction : ঔ')\n",
    "    elif res == 11:\n",
    "        print('prediction : ক')\n",
    "    elif res == 12:\n",
    "        print('prediction : খ')\n",
    "    elif res == 13:\n",
    "        print('prediction : গ')\n",
    "    elif res == 14:\n",
    "        print('prediction : ঘ')\n",
    "    elif res == 15:\n",
    "        print('prediction : ঙ')\n",
    "    elif res == 16:\n",
    "        print('prediction : চ')\n",
    "    elif res == 17:\n",
    "        print('prediction : ছ')\n",
    "    elif res == 18:\n",
    "        print('prediction : জ')\n",
    "    elif res == 19:\n",
    "        print('prediction : ঝ')\n",
    "    elif res == 20:\n",
    "        print('prediction : ঞ')\n",
    "    elif res == 21:\n",
    "        print('prediction : ট')\n",
    "    elif res == 22:\n",
    "        print('prediction : ঠ')\n",
    "    elif res == 23:\n",
    "        print('prediction : ড')\n",
    "    elif res == 24:\n",
    "        print('prediction : ঢ')\n",
    "    elif res == 25:\n",
    "        print('prediction : ণ')\n",
    "    elif res == 26:\n",
    "        print('prediction : ত')\n",
    "    elif res == 27:\n",
    "        print('prediction : থ')\n",
    "    elif res == 28:\n",
    "        print('prediction : দ')\n",
    "    elif res == 29:\n",
    "        print('prediction : ধ')\n",
    "    elif res == 30:\n",
    "        print('prediction : ন')\n",
    "    elif res == 31:\n",
    "        print('prediction : প')\n",
    "    elif res == 32:\n",
    "        print('prediction : ফ')\n",
    "    elif res == 33:\n",
    "        print('prediction : ব')\n",
    "    elif res == 34:\n",
    "        print('prediction : ভ')\n",
    "    elif res == 35:\n",
    "        print('prediction : ম')\n",
    "    elif res == 36:\n",
    "        print('prediction : য')\n",
    "    elif res == 37:\n",
    "        print('prediction : র')\n",
    "    elif res == 38:\n",
    "        print('prediction : ল')\n",
    "    elif res == 39:\n",
    "        print('prediction : শ')\n",
    "    elif res == 40:\n",
    "        print('prediction : ষ')\n",
    "    elif res == 41:\n",
    "        print('prediction : স')\n",
    "    elif res == 42:\n",
    "        print('prediction : হ')\n",
    "    elif res == 43:\n",
    "        print('prediction : ড়')\n",
    "    elif res == 44:\n",
    "        print('prediction : ঢ়')\n",
    "    elif res == 45:\n",
    "        print('prediction : য়')\n",
    "    elif res == 46:\n",
    "        print('prediction : ৎ')\n",
    "    elif res == 47:\n",
    "        print('prediction : ং')\n",
    "    elif res == 48:\n",
    "        print('prediction : ঃ')\n",
    "    else:\n",
    "        print('prediction : ঁ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def single_prediction(test_img):\n",
    "    test_img_arr = image.img_to_array(test_img)\n",
    "    test_img_arr = np.expand_dims(test_img_arr, axis = 0)\n",
    "    prediction = classifier.predict(test_img_arr)\n",
    "    result = np.argmax(prediction, axis = 1)\n",
    "    print(result)\n",
    "    #determine_character(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_created_image():\n",
    "    os.remove('C:\\\\Users\\Saunak\\Documents\\GitHub\\RegionalCharacterDetectionUsingCNN\\Dataset\\Dataset\\SinglePrediction\\image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_n_guess_the_character():\n",
    "    create_new_image()\n",
    "    test_img = image.load_img('C:\\\\Users\\Saunak\\Documents\\GitHub\\RegionalCharacterDetectionUsingCNN\\Dataset\\Dataset\\SinglePrediction\\image.jpg', target_size = (28, 28, 3))\n",
    "    single_prediction(test_img)\n",
    "    plt.imshow(test_img)\n",
    "    delete_created_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "prediction : ভ\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbiUlEQVR4nO3df2zU9R3H8dcV2qNA77CU9tpxsII/2ES7jEnXoAxDA3QJAWWJv5aAMRhZMUPmNCwqsi3phgkzGoZ/TWYi6kgEIslItEiJW2EBJYRsNpR1AwMtPyJ3pdCjtp/9wbjtoAjfL3f3bq/PR/JNuPt+3/2++fDtvfj2+/1+GnDOOQEAkGV51g0AAIYmAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmhls3cKW+vj4dP35cRUVFCgQC1u0AADxyzqmzs1MVFRXKy7v2ec6AC6Djx48rGo1atwEAuEnHjh3T+PHjr7l+wAVQUVGRpEuNh0Ih424AAF7F43FFo9Hk5/m1ZCyA1q9fr1deeUXt7e2qqqrS66+/runTp1+37vKP3UKhEAEEAIPY9S6jZOQmhPfee08rV67U6tWr9emnn6qqqkpz587VyZMnM7E7AMAglJEAWrdunZYuXarHH39c3/72t/XGG29o5MiR+sMf/pCJ3QEABqG0B9DFixe1f/9+1dbW/m8neXmqra1Vc3PzVdsnEgnF4/GUBQCQ+9IeQKdPn1Zvb6/KyspS3i8rK1N7e/tV2zc0NCgcDicX7oADgKHB/EHUVatWKRaLJZdjx45ZtwQAyIK03wVXUlKiYcOGqaOjI+X9jo4ORSKRq7YPBoMKBoPpbgMAMMCl/QyooKBA06ZNU2NjY/K9vr4+NTY2qqamJt27AwAMUhl5DmjlypVavHixvve972n69Ol69dVX1dXVpccffzwTuwMADEIZCaCHHnpIp06d0ksvvaT29nZ95zvf0Y4dO666MQEAMHQFnHPOuon/F4/HFQ6HFYvFmAkBAAahG/0cN78LDgAwNBFAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATw60bGCp6eno81xQUFGSgk/QJhUKea+LxeAY6SZ9gMOi5JpFIeK5xznmu6erq8lwzevRozzV+DRs2zHONn3H46quvslIjSfn5+b7qcGM4AwIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCyUh98DNJqJ/JSAe6gT6xqB9+Jhb1IxAIZGU/2dTb25uV/eTl8f/mbPM6KeuNTjLLvyQAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATQ3oy0lycEDIXRSIRzzXt7e0Z6AQYmrq7uz1tH4/Hdcstt1x3O86AAAAmCCAAgIm0B9DLL7+sQCCQskyZMiXduwEADHIZuQZ055136qOPPvrfToYP6UtNAIB+ZCQZhg8f7uvCMQBg6MjINaDDhw+roqJCkyZN0mOPPaajR49ec9tEIqF4PJ6yAAByX9oDqLq6Whs3btSOHTu0YcMGtbW16b777lNnZ2e/2zc0NCgcDieXaDSa7pYAAANQwDnnMrmDs2fPauLEiVq3bp2eeOKJq9YnEgklEonk63g8rmg0qlgsplAolMnWeA5okOA5IMBWb2+vp+0vPwd0vc/xjN8dMGbMGN1+++1qbW3td30wGFQwGMx0GwCAASbjzwGdO3dOR44cUXl5eaZ3BQAYRNIeQM8++6yampr0r3/9S3/961/1wAMPaNiwYXrkkUfSvSsAwCCW9h/BffHFF3rkkUd05swZjRs3Tvfee6/27NmjcePGpXtXAIBBLO0B9O6776b7S96QbN5Q4GdffX19nmu8TgAoSSNGjPBc45fXC5OSNGzYMM81I0eO9FyDS/Ly/P2Qw8/x6oef/goKCjzX+L3Xys849PT0eK4pLCz0XHPhwgXPNZL/sfDiRv9dmQsOAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACAiYz/QrpsycYEe9mWzYlF/fAzsagf+fn5nmv8TtSYa/xOKpqL308YeDgDAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYyJnZsDE4FBQUeK7p6enJQCcArHEGBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwASTkSKrLl686LnGz2Sk+fn5nmv8Ki4u9lzz5ZdfZqCT9AkEAp5rnHMZ6AS5jDMgAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJpiMFANeNicW9ePkyZOeawb63wnIBs6AAAAmCCAAgAnPAbR7927Nnz9fFRUVCgQC2rp1a8p655xeeukllZeXq7CwULW1tTp8+HC6+gUA5AjPAdTV1aWqqiqtX7++3/Vr167Va6+9pjfeeEN79+7VqFGjNHfuXHV3d990swCA3OH5JoS6ujrV1dX1u845p1dffVUvvPCCFixYIEl66623VFZWpq1bt+rhhx++uW4BADkjrdeA2tra1N7ertra2uR74XBY1dXVam5u7rcmkUgoHo+nLACA3JfWAGpvb5cklZWVpbxfVlaWXHelhoYGhcPh5BKNRtPZEgBggDK/C27VqlWKxWLJ5dixY9YtAQCyIK0BFIlEJEkdHR0p73d0dCTXXSkYDCoUCqUsAIDcl9YAqqysVCQSUWNjY/K9eDyuvXv3qqamJp27AgAMcp7vgjt37pxaW1uTr9va2nTgwAEVFxdrwoQJWrFihX7961/rtttuU2VlpV588UVVVFRo4cKF6ewbADDIeQ6gffv26f7770++XrlypSRp8eLF2rhxo5577jl1dXXpySef1NmzZ3Xvvfdqx44dGjFiRPq6BgAMegHnnLNu4v/F43GFw2HFYjGuByFnFRYWeq4Z6A9zD7CPEhi60c9x87vgAABDEwEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADAhOdfxwDg5p0+fdpzzejRozPQSf+6urqyti8MXZwBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMMFkpICB4cOz863nnPNV99VXX6W5E+BqnAEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwwWSkgIERI0Z4rvEzsWhvb6/nGil7k6ViaOMMCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAlmHERO8jNxpyQFg0HPNYFAwHONn0lCe3p6PNfk5+d7rgGyhTMgAIAJAggAYMJzAO3evVvz589XRUWFAoGAtm7dmrJ+yZIlCgQCKcu8efPS1S8AIEd4DqCuri5VVVVp/fr119xm3rx5OnHiRHJ55513bqpJAEDu8XwTQl1dnerq6r52m2AwqEgk4rspAEDuy8g1oF27dqm0tFR33HGHli1bpjNnzlxz20QioXg8nrIAAHJf2gNo3rx5euutt9TY2Kjf/va3ampqUl1d3TVvO21oaFA4HE4u0Wg03S0BAAaggPP7wIQuPf+wZcsWLVy48Jrb/POf/9TkyZP10Ucfafbs2VetTyQSSiQSydfxeFzRaFSxWEyhUMhvaxjiBvpzQBcuXPBc4+fZIZ4DgoV4PK5wOHzdz/GM34Y9adIklZSUqLW1td/1wWBQoVAoZQEA5L6MB9AXX3yhM2fOqLy8PNO7AgAMIp7vgjt37lzK2UxbW5sOHDig4uJiFRcXa82aNVq0aJEikYiOHDmi5557Trfeeqvmzp2b1sYBAIOb5wDat2+f7r///uTrlStXSpIWL16sDRs26ODBg/rjH/+os2fPqqKiQnPmzNGvfvUrXz9bBwDkrpu6CSETbvTiFYaOkSNHeq7xe1h3d3dnZV9+bkIoLCz0XANYGDA3IQAA0B8CCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAnPv44BuBl+fn11NmVrcnhmtgY4AwIAGCGAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCyUih3t5eX3UjR45McyfpM2rUKF91fiZLvXjxouea/Px8zzVAruEMCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkmI4WKiop81fmZhDNburq6fNX5mYy0oKDAc42fCWDz8vj/InILRzQAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATTEYKnT9/3ledn4k7/Ux82tnZ6bnGL+ec5xo/k5GWlZV5rrlw4YLnmnPnznmuAbKFMyAAgAkCCABgwlMANTQ06J577lFRUZFKS0u1cOFCtbS0pGzT3d2t+vp6jR07VqNHj9aiRYvU0dGR1qYBAIOfpwBqampSfX299uzZow8//FA9PT2aM2dOyi//euaZZ/TBBx9o8+bNampq0vHjx/Xggw+mvXEAwOAWcH6uuv7XqVOnVFpaqqamJs2cOVOxWEzjxo3Tpk2b9KMf/UiS9Pnnn+tb3/qWmpub9f3vf/+6XzMejyscDisWiykUCvltDVmQizch+OHnJgQ/xzY3IWCwuNHP8Zu6BhSLxSRJxcXFkqT9+/erp6dHtbW1yW2mTJmiCRMmqLm5ud+vkUgkFI/HUxYAQO7zHUB9fX1asWKFZsyYoalTp0qS2tvbVVBQoDFjxqRsW1ZWpvb29n6/TkNDg8LhcHKJRqN+WwIADCK+A6i+vl6HDh3Su+++e1MNrFq1SrFYLLkcO3bspr4eAGBw8PUg6vLly7V9+3bt3r1b48ePT74fiUR08eJFnT17NuUsqKOjQ5FIpN+vFQwGFQwG/bQBABjEPJ0BOee0fPlybdmyRTt37lRlZWXK+mnTpik/P1+NjY3J91paWnT06FHV1NSkp2MAQE7wdAZUX1+vTZs2adu2bSoqKkpe1wmHwyosLFQ4HNYTTzyhlStXqri4WKFQSE8//bRqampu6A44AMDQ4SmANmzYIEmaNWtWyvtvvvmmlixZIkn63e9+p7y8PC1atEiJREJz587V73//+7Q0CwDIHTf1HFAm8BxQbuvr68vKfkpKSnzV+Xlu5quvvvJc4+fbzs+10kQi4blG8tcfcFlWngMCAMAvAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJX78RFfArLy87/+f58ssvfdXl5+d7rhk+3Pu3kZ+aCxcueK7xKxAIZKXm1KlTnmvGjh3ruQYDE2dAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATDAZKXKSc85XXSKR8FwzYsQIzzU9PT2eawY6P2NeUlLiuSYWi3muCYVCnmuQeZwBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMMFkpMD/CQaDnmv8TCyan5/vuWagKyoq8lxz5swZzzW5OHZDFWdAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATDAZKXCThg/3/m3knMtAJ1cbNWqUr7rz5897ronH4772haGLMyAAgAkCCABgwlMANTQ06J577lFRUZFKS0u1cOFCtbS0pGwza9YsBQKBlOWpp55Ka9MAgMHPUwA1NTWpvr5ee/bs0Ycffqienh7NmTNHXV1dKdstXbpUJ06cSC5r165Na9MAgMHP09XTHTt2pLzeuHGjSktLtX//fs2cOTP5/siRIxWJRNLTIQAgJ93UNaBYLCZJKi4uTnn/7bffVklJiaZOnapVq1Z97R01iURC8Xg8ZQEA5D7ft2H39fVpxYoVmjFjhqZOnZp8/9FHH9XEiRNVUVGhgwcP6vnnn1dLS4vef//9fr9OQ0OD1qxZ47cNAMAgFXA+H0hYtmyZ/vznP+uTTz7R+PHjr7ndzp07NXv2bLW2tmry5MlXrU8kEkokEsnX8Xhc0WhUsVhMoVDIT2sA/iubzwFl69kmDHzxeFzhcPi6n+O+zoCWL1+u7du3a/fu3V8bPpJUXV0tSdcMoGAwqGAw6KcNAMAg5imAnHN6+umntWXLFu3atUuVlZXXrTlw4IAkqby83FeDAIDc5CmA6uvrtWnTJm3btk1FRUVqb2+XJIXDYRUWFurIkSPatGmTfvjDH2rs2LE6ePCgnnnmGc2cOVN33313Rv4CAIDBydM1oEAg0O/7b775ppYsWaJjx47pxz/+sQ4dOqSuri5Fo1E98MADeuGFF274es6N/uwQwPVxDQgWMnIN6HoHWDQaVVNTk5cvCQAYopgNG8hhV85SAgwkTEYKADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADAxHDrBq7knJMkxeNx404AAH5c/vy+/Hl+LQMugDo7OyVJ0WjUuBMAwM3o7OxUOBy+5vqAu15EZVlfX5+OHz+uoqIiBQKBlHXxeFzRaFTHjh1TKBQy6tAe43AJ43AJ43AJ43DJQBgH55w6OztVUVGhvLxrX+kZcGdAeXl5Gj9+/NduEwqFhvQBdhnjcAnjcAnjcAnjcIn1OHzdmc9l3IQAADBBAAEATAyqAAoGg1q9erWCwaB1K6YYh0sYh0sYh0sYh0sG0zgMuJsQAABDw6A6AwIA5A4CCABgggACAJgggAAAJgZNAK1fv17f/OY3NWLECFVXV+tvf/ubdUtZ9/LLLysQCKQsU6ZMsW4r43bv3q358+eroqJCgUBAW7duTVnvnNNLL72k8vJyFRYWqra2VocPH7ZpNoOuNw5Lliy56viYN2+eTbMZ0tDQoHvuuUdFRUUqLS3VwoUL1dLSkrJNd3e36uvrNXbsWI0ePVqLFi1SR0eHUceZcSPjMGvWrKuOh6eeesqo4/4NigB67733tHLlSq1evVqffvqpqqqqNHfuXJ08edK6tay78847deLEieTyySefWLeUcV1dXaqqqtL69ev7Xb927Vq99tpreuONN7R3716NGjVKc+fOVXd3d5Y7zazrjYMkzZs3L+X4eOedd7LYYeY1NTWpvr5ee/bs0Ycffqienh7NmTNHXV1dyW2eeeYZffDBB9q8ebOampp0/PhxPfjgg4Zdp9+NjIMkLV26NOV4WLt2rVHH1+AGgenTp7v6+vrk697eXldRUeEaGhoMu8q+1atXu6qqKus2TElyW7ZsSb7u6+tzkUjEvfLKK8n3zp4964LBoHvnnXcMOsyOK8fBOecWL17sFixYYNKPlZMnTzpJrqmpyTl36d8+Pz/fbd68ObnNP/7xDyfJNTc3W7WZcVeOg3PO/eAHP3A//elP7Zq6AQP+DOjixYvav3+/amtrk+/l5eWptrZWzc3Nhp3ZOHz4sCoqKjRp0iQ99thjOnr0qHVLptra2tTe3p5yfITDYVVXVw/J42PXrl0qLS3VHXfcoWXLlunMmTPWLWVULBaTJBUXF0uS9u/fr56enpTjYcqUKZowYUJOHw9XjsNlb7/9tkpKSjR16lStWrVK58+ft2jvmgbcZKRXOn36tHp7e1VWVpbyfllZmT7//HOjrmxUV1dr48aNuuOOO3TixAmtWbNG9913nw4dOqSioiLr9ky0t7dLUr/Hx+V1Q8W8efP04IMPqrKyUkeOHNEvfvEL1dXVqbm5WcOGDbNuL+36+vq0YsUKzZgxQ1OnTpV06XgoKCjQmDFjUrbN5eOhv3GQpEcffVQTJ05URUWFDh48qOeff14tLS16//33DbtNNeADCP9TV1eX/PPdd9+t6upqTZw4UX/605/0xBNPGHaGgeDhhx9O/vmuu+7S3XffrcmTJ2vXrl2aPXu2YWeZUV9fr0OHDg2J66Bf51rj8OSTTyb/fNddd6m8vFyzZ8/WkSNHNHny5Gy32a8B/yO4kpISDRs27Kq7WDo6OhSJRIy6GhjGjBmj22+/Xa2trdatmLl8DHB8XG3SpEkqKSnJyeNj+fLl2r59uz7++OOUX98SiUR08eJFnT17NmX7XD0erjUO/amurpakAXU8DPgAKigo0LRp09TY2Jh8r6+vT42NjaqpqTHszN65c+d05MgRlZeXW7diprKyUpFIJOX4iMfj2rt375A/Pr744gudOXMmp44P55yWL1+uLVu2aOfOnaqsrExZP23aNOXn56ccDy0tLTp69GhOHQ/XG4f+HDhwQJIG1vFgfRfEjXj33XddMBh0GzdudH//+9/dk08+6caMGePa29utW8uqn/3sZ27Xrl2ura3N/eUvf3G1tbWupKTEnTx50rq1jOrs7HSfffaZ++yzz5wkt27dOvfZZ5+5f//73845537zm9+4MWPGuG3btrmDBw+6BQsWuMrKSnfhwgXjztPr68ahs7PTPfvss665udm1tbW5jz76yH33u991t912m+vu7rZuPW2WLVvmwuGw27Vrlztx4kRyOX/+fHKbp556yk2YMMHt3LnT7du3z9XU1LiamhrDrtPveuPQ2trqfvnLX7p9+/a5trY2t23bNjdp0iQ3c+ZM485TDYoAcs65119/3U2YMMEVFBS46dOnuz179li3lHUPPfSQKy8vdwUFBe4b3/iGe+ihh1xra6t1Wxn38ccfO0lXLYsXL3bOXboV+8UXX3RlZWUuGAy62bNnu5aWFtumM+DrxuH8+fNuzpw5bty4cS4/P99NnDjRLV26NOf+k9bf31+Se/PNN5PbXLhwwf3kJz9xt9xyixs5cqR74IEH3IkTJ+yazoDrjcPRo0fdzJkzXXFxsQsGg+7WW291P//5z10sFrNt/Ar8OgYAgIkBfw0IAJCbCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmPgPPQsxT82WTTYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_n_guess_the_character()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d45f43cf4df4209586cf220d0f9bc2e9e2f42bfdeffbbcd11e52e62333eff2c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
